{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Architecture (Machine Translation Example)\n",
    "\n",
    "In the previous example, we saw the primitive text generation example with RNN, in which each word is selected only by the previous sequence of words.<br>\n",
    "But, in real text generation, the word will be often decided with other information (context) - i.e, conditioned text generation.\n",
    "\n",
    "Let's see the following architecture.<br>\n",
    "In this architecture, the word is selected by both the sequence of words and context information ```c```.<br>\n",
    "For instance, when it generates text for movie review, the conditioned context ```c``` might be a movie. When it generates the answer for questioning, it might be genre - such as, \"computer science\", \"sports\", \"politics\", etc. It will then be able to generate more appropriate text depending on the genre (theme) of the contents. \n",
    "\n",
    "![RNN with conditioned context](./images/conditioned_context.png)\n",
    "\n",
    "The encoder-decoder framework is a trainer for text generation with **sequence-to-sequence** conditioned context as follows. (See the following diagram.)\n",
    "\n",
    "For instance, when you want to translate French to English, first it generates conditioned context ```c``` from a source sentence (which is the sequence of length m).<br>\n",
    "This is called **encoder**, and the encoder summarizes a French sentence as a context vector ```c```.<br>\n",
    "Next it will predict English sentence (which is the sequence of length n) using the generated context ```c```, and this is called **decoder**.<br>\n",
    "As you can see below, the source length (m) and target length (n) might differ in this training.\n",
    "\n",
    "![encoder-decoder architecture](./images/encoder_decoder.png)\n",
    "\n",
    "This encoder-decoder architecture can be used in forms of sequence-to-sequence problems, and is used in a lot of scenarios, such as, auto-response (smart reply or question-answering), inflection, image captioning, etc. (In image captioning task, an image input will be encoded as a vector with convolution network.)<br>\n",
    "It can also be used for generating a vector representation (in which encoder-decoder is trained to reconstruct the input sentence) or text generation, both which have been seen in the previous examples.<br>\n",
    "A variety of today's language tasks depends on encoder-decoder architecture and attention, which will be discussed in the next example.\n",
    "\n",
    "In this example, I'll implement simple sequence-to-sequence trainer in machine translation task. Here I only use encoder-decoder framework and I note that the result might not be so good.<br>\n",
    "In the next tutorial, we'll add more sophisticated architecture \"attention\" (also, widely used in today's NLP) in this encoder-decoder model.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/nlp-tutorials/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.6.2 numpy nltk matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, I use Engligh-French dataset by [Anki](https://www.manythings.org/anki/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-09-02 21:11:54--  http://www.manythings.org/anki/fra-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6612164 (6.3M) [application/zip]\n",
      "Saving to: ‘fra-eng.zip’\n",
      "\n",
      "fra-eng.zip         100%[===================>]   6.31M  8.38MB/s    in 0.8s    \n",
      "\n",
      "2022-09-02 21:11:56 (8.38 MB/s) - ‘fra-eng.zip’ saved [6612164/6612164]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  fra-eng.zip\n",
      "  inflating: fra-eng/_about.txt      \n",
      "  inflating: fra-eng/fra.txt         \n"
     ]
    }
   ],
   "source": [
    "!unzip fra-eng.zip -d fra-eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\r\n",
      "Go.\tMarche.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)\r\n",
      "Go.\tBouge !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)\r\n",
      "Hi.\tSalut !\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\r\n",
      "Hi.\tSalut.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 fra-eng/fra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194513 fra-eng/fra.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l fra-eng/fra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Va !', 'Go.'], dtype='<U349')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "pathobj = Path(\"fra-eng/fra.txt\")\n",
    "text_all = pathobj.read_text(encoding=\"utf-8\")\n",
    "lines = text_all.splitlines()\n",
    "train_data = [line.split(\"\\t\") for line in lines]\n",
    "train_data = np.array(train_data)[:,[1,0]]\n",
    "# print first row\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this training set, text length in the latter part is longer (and includes multiple sentences) than the former part.<br>\n",
    "Therefore I shuffle entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Ce n'était pas possible.\", \"That wasn't possible.\"], dtype='<U349')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(train_data)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data consists of multiple sentences, it converts to a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tsmatsuz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.data\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "tokenizer_en = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "tokenizer_fr = nltk.data.load(\"tokenizers/punkt/french.pickle\")\n",
    "fr_list = []\n",
    "en_list = []\n",
    "for x in train_data:\n",
    "    x1 = tokenizer_fr.tokenize(x[0])\n",
    "    x2 = tokenizer_en.tokenize(x[1])\n",
    "    if len(x1) == len(x2):\n",
    "        fr_list += x1\n",
    "        en_list += x2\n",
    "train_data = np.column_stack((fr_list, en_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the better performance (accuracy), I standarize the input text as follows.\n",
    "- Make all words to lowercase in order to reduce words\n",
    "- Make \"-\" (hyphen) to space\n",
    "- Remove all punctuation except \" ' \" (e.g, Ken's bag, ces't, ...)\n",
    "\n",
    "> Note : To make simplify, I have skipped other pre-processing, such as, N-gram detection (see [this example](./04_ngram_cnn.ipynb)), polysemy processing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"ce n'était pas possible\", \"that wasn't possible\"], dtype='<U250')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "train_data = np.char.lower(train_data)\n",
    "train_data = np.char.replace(train_data, \"-\", \" \")\n",
    "for x in string.punctuation.replace(\"'\", \"\"):\n",
    "    train_data = np.char.replace(train_data, x, \"\")\n",
    "for x in \"«»\":\n",
    "    train_data = np.char.replace(train_data, x, \"\")\n",
    "train_data = np.char.strip(train_data)\n",
    "# print first row\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ```[START]``` and ```[END]``` tokens in string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"[START] ce n'était pas possible [END]\",\n",
       "       \"[START] that wasn't possible [END]\"], dtype='<U264')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.array([[\" \".join([\"[START]\", x, \"[END]\"]), \" \".join([\"[START]\", y, \"[END]\"])] for x, y in train_data])\n",
    "# print first row\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sequence inputs\n",
    "\n",
    "We will generate the sequence of word's indices (i.e, tokenize) from text.\n",
    "\n",
    "![Index vectorize](images/index_vectorize2.png?raw=true)\n",
    "\n",
    "First, we build word's vectorizer for both source text (French) and target text (English) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "max_word = 10000\n",
    "\n",
    "source_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_word,\n",
    "    output_sequence_length=None, # maximum length of sequences\n",
    "    output_mode=\"int\")\n",
    "source_vectorization.adapt(train_data[:,0])\n",
    "\n",
    "target_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_word,\n",
    "    output_sequence_length=None, # maximum length of sequences\n",
    "    output_mode=\"int\")\n",
    "target_vectorization.adapt(train_data[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we vectorize sentence into integer's sequence as follows.<br>\n",
    "In this example, we create fixed size of sequence (padded by 0) in each row.\n",
    "\n",
    "![Index vectorize](images/index_vectorize2.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  3  17 300   6 478   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0], shape=(45,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[  2  11 224 515   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0], shape=(38,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "train_source = source_vectorization(train_data[:,0])\n",
    "train_target = target_vectorization(train_data[:,1])\n",
    "# print first row\n",
    "print(train_source[0])\n",
    "print(train_target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make TensorFlow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_data = tf.data.Dataset.from_tensor_slices((train_source, train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate label (y) for training.\n",
    "\n",
    "As I have mentioned above, we should finally predict the next word in target sentence (English) using current word and encoded context.<br>\n",
    "We then create the following label (y) in each row.\n",
    "\n",
    "<u>input - list of current words</u> :\n",
    "```\n",
    "[2, 7, 5, 3, 0, ... , 0]\n",
    "```\n",
    "\n",
    "<u>output (y) - list of next words</u> :\n",
    "```\n",
    "[7, 5, 3, 0, 0, ... , 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** X *****\n",
      "(<tf.Tensor: shape=(45,), dtype=int64, numpy=\n",
      "array([  3,  17, 300,   6, 478,   2,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0])>, <tf.Tensor: shape=(38,), dtype=int64, numpy=\n",
      "array([  2,  11, 224, 515,   3,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>)\n",
      "***** y *****\n",
      "tf.Tensor(\n",
      "[ 11 224 515   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0], shape=(38,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def add_label(x_source, x_target):\n",
    "    y = tf.slice(x_target, begin=[1], size=[len(x_target) - 1])\n",
    "    y = tf.concat([y, [0]], axis=0)\n",
    "    return (x_source, x_target), y\n",
    "train_tf_data = train_tf_data.map(lambda src, tar: add_label(src, tar))\n",
    "# print first row\n",
    "for x, y in train_tf_data.take(1):\n",
    "    print(\"***** X *****\")\n",
    "    print(x)\n",
    "    print(\"***** y *****\")\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert label y into one-hot vector (shape (max_word,)).\n",
    "\n",
    "y (before) :\n",
    "```\n",
    "[4, 1, 3, 0]\n",
    "```\n",
    "\n",
    "y (after) :\n",
    "```\n",
    "[\n",
    "  [0,0,0,0,1, ... ,0],\n",
    "  [0,1,0,0,0, ... ,0],\n",
    "  [0,0,0,1,0, ... ,0],\n",
    "  [1,0,0,0,0, ... ,0]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]], shape=(38, 10000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(x, y):\n",
    "    y_new = tf.one_hot(y, depth=max_word)\n",
    "    return x, y_new\n",
    "train_tf_data = train_tf_data.map(lambda x, y: to_one_hot(x, y))\n",
    "# print y in first row\n",
    "for x, y in train_tf_data.take(1):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Encoder-Decoder\n",
    "\n",
    "Now we build a model with encoder-decoder architecture as follows.\n",
    "\n",
    "- Context is generated in encoder.\n",
    "- Context is concatenated with inputs (words) and passed into RNN layer.\n",
    "- RNN outputs (in all units in sequence) is passed into dense (FCNet) layer and generate the sequence of next words.\n",
    "- Calculate loss between predicted next words and the true values of next words, and then proceed to train.\n",
    "\n",
    "![the trainer architecture of machine translation](./images/machine_translation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build encoder model.\n",
    "\n",
    "In the following ```tf.keras.layers.GRU``` layer, the shape of RNN input is expected to be ```(batch_size, sequence_length, input_dimension)```. By setting ```stateful=True```, the last state at index i in batch is used as initial state for index i in the following batch.<br>\n",
    "Here we then set ```stateful=False```. (Because the sequence in the following batch doesn't depend on the sequence in previous batch.)\n",
    "\n",
    "On this example, I note that only the last output in sequence is required in encoder model.<br>\n",
    "Therefore I set ```return_sequences=False``` in RNN (GRU layer).\n",
    "\n",
    "![final output in encoder](./images/encoder_final.png)\n",
    "\n",
    "Remind that the length of each sequence differs in each row and it's padded by zero.<br>\n",
    "Therefore, here I create mask, in which the element is TRUE when the word exists and FALSE when the word is missing.<br>\n",
    "By passing mask into RNN, the computation will be skipped at FALSE elements.\n",
    "\n",
    "> Note : You can also set encoder's final state as decoder's initial state.<br>\n",
    "> In this example, I'll discard encoder's final state in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            self.vocab_size,\n",
    "            embedding_dim,\n",
    "            mask_zero=True,\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.rnn = tf.keras.layers.GRU(\n",
    "            rnn_units,\n",
    "            use_bias=True,\n",
    "            return_sequences=False,  # see above !\n",
    "            return_state=True,\n",
    "            stateful=False,  # not to inherit states between batches\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, states=None, training=False, return_state=False):\n",
    "        inputs_emb = self.embedding(inputs, training=training)\n",
    "        mask = self.embedding.compute_mask(inputs)\n",
    "        if states is None:\n",
    "            outputs, new_states = self.rnn(inputs_emb, mask=mask, training=training)\n",
    "        else:\n",
    "            outputs, new_states = self.rnn(inputs_emb, mask=mask, initial_state=states, training=training)\n",
    "        if return_state:\n",
    "            return outputs, new_states  # This is used in prediction\n",
    "        else:\n",
    "            return outputs              # This is used in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we build decoder model.\n",
    "\n",
    "The decoder receives encoder's final output, and this is commonly used in all units in sequence.\n",
    "\n",
    "In each unit, encoder's final output (context) is concatenated with input (word embedding), as I have mentioned above.<br>\n",
    "The concatenated vector is then passed into RNN. The output of RNN is then passed into dense network (fully-connected network, FCNet) and it generates the next word's prediction.\n",
    "\n",
    "![the trainer architecture of machine translation](./images/machine_translation.png)\n",
    "\n",
    "Same as above, mask (this time, mask in target sequence) is passed into RNN and the computation will be skipped at the missing elements in sequence.\n",
    "\n",
    "> Note : Unlike encoder, ```return_sequences``` in RNN layer should be ```True```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            self.vocab_size,\n",
    "            embedding_dim,\n",
    "            mask_zero=True,\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.rnn = tf.keras.layers.GRU(\n",
    "            rnn_units,\n",
    "            use_bias=True,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            stateful=False,  # not to inherit states between batches\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.dense1 = tf.keras.layers.Dense(\n",
    "            rnn_units,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.dense2 = tf.keras.layers.Dense(\n",
    "            self.vocab_size,\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, states=None, training=False, return_state=False):\n",
    "        inputs_target, enc_outputs = inputs\n",
    "        # process embedding\n",
    "        inputs_emb = self.embedding(inputs_target, training=training)\n",
    "        # I note that the shape of enc_outputs is (batch_size, rnn_unit_size).\n",
    "        # Convert shape into (batch_size, sequence_size, rnn_unit_size) for concat\n",
    "        enc_outputs = tf.expand_dims(enc_outputs, axis=1) # expand shape to [batch_size, 1, rnn_unit_size]\n",
    "        sequence_size = tf.shape(inputs_target)[1]\n",
    "        enc_outputs = tf.tile(enc_outputs, multiples=[1,sequence_size,1]) # expand shape at axis=1\n",
    "        ctx_and_emb = tf.concat([enc_outputs, inputs_emb], axis=-1) # concat\n",
    "        # process rnn\n",
    "        mask = self.embedding.compute_mask(inputs_target)\n",
    "        if states is None:\n",
    "            rnn_outputs, new_states = self.rnn(ctx_and_emb, mask=mask, training=training)\n",
    "        else:\n",
    "            rnn_outputs, new_states = self.rnn(ctx_and_emb, mask=mask, initial_state=states, training=training)\n",
    "        # I note that dense is calculated for all outputs in sequence without masking\n",
    "        outputs = self.dense1(rnn_outputs, training=training)\n",
    "        outputs = self.dense2(outputs, training=training)\n",
    "        if return_state:\n",
    "            return outputs, mask, new_states  # This is used in prediction\n",
    "        else:\n",
    "            return outputs, mask              # This is used in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put it all together and run training.\n",
    "\n",
    "I note that the loss computation is also masked. (i.e, The loss at missing words are ignored.)\n",
    "\n",
    "> Note : In the following example, I'm writing a training loop from scratch, but you can also build TensorFlow custom model for this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - loss   1.811149\n",
      "Epoch 2/5 - loss   0.975240\n",
      "Epoch 3/5 - loss   0.659642\n",
      "Epoch 4/5 - loss   0.472957\n",
      "Epoch 5/5 - loss   0.640757\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "n_epoch = 5\n",
    "shuffle_buffer_size = 5000\n",
    "train_batch_size = 64\n",
    "loss_records = []\n",
    "\n",
    "enc_model = Encoder(\n",
    "    vocab_size=max_word,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "dec_model = Decoder(\n",
    "    vocab_size=max_word,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction=tf.keras.losses.Reduction.NONE\n",
    ")\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "### I don't use train_tf_data.repeat(n_epoch) and run shuffle in each epoch,\n",
    "### because I want to check result in each epoch\n",
    "for epoch in range(n_epoch):\n",
    "    tf_data_epoch = train_tf_data.shuffle(shuffle_buffer_size).batch(train_batch_size)\n",
    "    iterator = iter(tf_data_epoch)\n",
    "    while True:\n",
    "        with tf.GradientTape() as enc_tape, tf.GradientTape() as dec_tape:\n",
    "            # get next batch\n",
    "            try:\n",
    "                input_batch_x, input_batch_y = iterator.get_next()\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                loop_f = False\n",
    "                break\n",
    "            input_source, input_target = input_batch_x\n",
    "            # process encoder\n",
    "            enc_outputs = enc_model(\n",
    "                input_source,\n",
    "                training=True)\n",
    "            # process decoder\n",
    "            logits, mask = dec_model(\n",
    "                (input_target , enc_outputs),\n",
    "                training=True)\n",
    "            # calculate masked loss\n",
    "            loss = loss_func(\n",
    "                input_batch_y,\n",
    "                logits) # shape of loss is (batch_size, sequence_size)\n",
    "            mask_float = tf.cast(mask, tf.float32) # True -> 1.0, False -> 0.0\n",
    "            loss = loss * mask_float\n",
    "            loss = tf.math.reduce_sum(loss, axis=1) # shape of loss is (batch_size, )\n",
    "            loss = loss / tf.math.reduce_sum(mask_float, axis=1)\n",
    "            # get gradient\n",
    "            grad = enc_tape.gradient(\n",
    "                loss,\n",
    "                enc_model.trainable_variables+dec_model.trainable_variables\n",
    "            )\n",
    "        # apply gradient\n",
    "        opt.apply_gradients(zip(grad, enc_model.trainable_variables+dec_model.trainable_variables))\n",
    "        # record result\n",
    "        batch_average_loss = tf.math.reduce_mean(loss).numpy().tolist()\n",
    "        print(\"Epoch {}/{} - loss {loss:10.6f}\".format(epoch+1, n_epoch, loss=batch_average_loss), end=\"\\r\")\n",
    "        loss_records.append(batch_average_loss)\n",
    "    # add line break\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training has completed, show how loss is optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc26c8d3f60>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#loss_list = loss_records[:10000]\n",
    "loss_list = loss_records\n",
    "\n",
    "loss_average = []\n",
    "for i in range(len(loss_list)):\n",
    "    avg_list = np.empty(shape=(1,), dtype=int)\n",
    "    if i < 50:\n",
    "        avg_list = loss_list[:i+1]\n",
    "    else:\n",
    "        avg_list = loss_list[i-49:i+1]\n",
    "    loss_average.append(np.average(avg_list))\n",
    "plt.plot(loss_list)\n",
    "plt.plot(loss_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Text\n",
    "\n",
    "Now translate text (French) to English with trained model.<br>\n",
    "Here I simply translate several sentences. (All these sentences are not in training set.)\n",
    "\n",
    "The metrics to evaluate text generation task is not so easy. (Because simply checking an exact match to a reference text is not optimal.)<br>\n",
    "Use some common metrics available in these cases, such as, BLEU or ROUGE.\n",
    "\n",
    "> Note : Here I use greedy search and this will sometimes lead to wrong sequence. For drawbacks and solutions, see note in [this example](./05_language_model_basic.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def translate(sentence):\n",
    "    # preprocess french\n",
    "    input_text_fr = sentence\n",
    "    input_text_fr = input_text_fr.lower()\n",
    "    input_text_fr = \" \".join([\"[START]\", input_text_fr, \"[END]\"])\n",
    "\n",
    "    text_seq_fr = source_vectorization(input_text_fr)\n",
    "    text_seq_fr = tf.expand_dims(text_seq_fr, axis=0)\n",
    "\n",
    "    # process encoder\n",
    "    enc_outputs = enc_model(text_seq_fr)\n",
    "\n",
    "    # process decoder\n",
    "    vocab_list_en = target_vectorization.get_vocabulary()\n",
    "    states = None\n",
    "    prev_idx_en = target_vectorization(\"[START]\")\n",
    "    end_num_en = target_vectorization(\"[END]\").numpy().tolist()[0]\n",
    "    #text_seq_en = []\n",
    "    #text_seq_en = tf.expand_dims(text_seq_en[len(text_seq_en) - 1], axis=0)\n",
    "    while True:\n",
    "        y, mask, states = dec_model(\n",
    "            (tf.expand_dims(prev_idx_en, axis=0), enc_outputs),\n",
    "            states=states,\n",
    "            return_state=True)\n",
    "        prev_idx_en = np.argmax(y[0][0])\n",
    "        if prev_idx_en.item() == end_num_en:\n",
    "            break\n",
    "        print(vocab_list_en[prev_idx_en.item()], end=\" \")\n",
    "        prev_idx_en = tf.convert_to_tensor([prev_idx_en])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like the guitar \n",
      "\n",
      "he lives in japan \n",
      "\n",
      "this pen is next to his way \n",
      "\n",
      "this is my favorite song \n",
      "\n",
      "he drives a car and a cheap store \n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(\"j'aime la guitare\") # i like guitar\n",
    "translate(\"il vit au japon\") # he lives in Japan\n",
    "translate(\"ce stylo est utilisé par lui\") # this pen is used by him\n",
    "translate(\"c'est ma chanson préférée\") # that's my favorite song\n",
    "translate(\"il conduit une voiture et va à new york\") # he drives a car and goes to new york"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
