{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation with Attention\n",
    "\n",
    "In the [previous example](./07_encoder_decoder.ipynb), we saw sequence-to-sequence encoder-decoder architecture in machine translation.<br>\n",
    "In the previous example, the input sequence is encoded into a single context, and this context is used for decoding in all units in generated sequence.\n",
    "\n",
    "This architecture will not be flexible, and also not scalable. For instance, in case of machine translation, it will be difficult to translate a long text (such as, translate multiple sentences at once) unlike human translation. (Because a single context will not be enough to represent entire text, when the text becomes larger.)\n",
    "\n",
    "By introducing attention architecture, this constraint can be relaxed.<br>\n",
    "The attention is more elaborative and widely used architecture in today's NLP, and a lot of tasks (such as, machine translation, smart reply, etc) are researched by adding attention mechanism and worked well today.\n",
    "\n",
    "In the overview outline of attention architecture, the different context can be used in each units in sequence for decoding as follows.\n",
    "\n",
    "![encoder-decoder with attention architecture](./images/encoder_decoder_attention.png)\n",
    "\n",
    "Within attention, first it will generate $\\{ \\alpha_j^i \\}\\;(i=1,\\ldots,n)$, in which $\\sum_i \\alpha_j^i = 1$, with dense net (FCNet) and softmax activation, where $n$ is the number of encoder's outputs and $j$ is time step in sequence. (See the following diagram.)<br>\n",
    "To say in abstraction, $\\{ \\alpha_j^i \\}\\;(i=1,\\ldots,n)$ means an alignment's weight at j-th time step for each source sequence outputs, $o_1^{\\prime}, o_2^{\\prime}, \\ldots, o_n^{\\prime}$.<br>\n",
    "(This $\\{ \\alpha_j^i \\}\\;(i=1,\\ldots,n)$ is then called attention weights.)\n",
    "\n",
    "> Note : See [here](https://tsmatz.wordpress.com/2017/08/30/glm-regression-logistic-poisson-gaussian-gamma-tutorial-with-r/) for softmax function. (It's used for normalizing outputs (sum to one).)\n",
    "\n",
    "And it then generates context $c_j$ at j-th time step by $ c_j = \\sum_i^n \\alpha_j^i \\cdot o_i^{\\prime} $.\n",
    "\n",
    "![soft attention architecture](./images/soft_attention.png)\n",
    "\n",
    "> Note : This architecture is called *soft attention*, which is the first attention introduced in the context of sequence-to-sequence generation. (See Bahdanau et al.)<br>\n",
    "> There exist a lot of variants in attention architecture. See [this post](https://tsmatz.wordpress.com/2021/11/11/reinforcement-learning-visual-attention-in-minecraft/) for self-attention architecture (**transformer**), which is widely used SOTA architecture in a lot of today's NLP tasks.\n",
    "\n",
    "With this network, it can focus on specific components in source sequence.<br>\n",
    "For instance, in case of the following French-to-English machine translation, the 3rd units in sequence (\"don't\" in English) will focus on 3rd and 5th components in original sequence, because the word \"don't\" will strongly focus on the source French \"ne\" and \"pas\". But others (\"je\" or \"comprends\") are also weakly referred, because it's used for determining not \"doesn't\" or not \"isn't\".<br>\n",
    "As a result, the attention weights $\\{ \\alpha_j^i \\}\\;(i=1,\\ldots,n)$ will be large for the source components \"ne\" and \"pas\", and will be small for the source components \"je\" and \"comprends\".\n",
    "\n",
    "![attend in machine translation](./images/attend_image.png)\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/nlp-tutorials/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.6.2 numpy nltk matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, I use Engligh-French dataset by [Anki](https://www.manythings.org/anki/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-09-06 19:13:30--  http://www.manythings.org/anki/fra-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6720195 (6.4M) [application/zip]\n",
      "Saving to: ‘fra-eng.zip’\n",
      "\n",
      "fra-eng.zip         100%[===================>]   6.41M  7.52MB/s    in 0.9s    \n",
      "\n",
      "2022-09-06 19:13:31 (7.52 MB/s) - ‘fra-eng.zip’ saved [6720195/6720195]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  fra-eng.zip\n",
      "  inflating: fra-eng/_about.txt      \n",
      "  inflating: fra-eng/fra.txt         \n"
     ]
    }
   ],
   "source": [
    "!unzip fra-eng.zip -d fra-eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\r\n",
      "Go.\tMarche.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)\r\n",
      "Go.\tEn route !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)\r\n",
      "Go.\tBouge !\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)\r\n",
      "Hi.\tSalut !\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 fra-eng/fra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197463 fra-eng/fra.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l fra-eng/fra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Va !', 'Go.'], dtype='<U349')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "pathobj = Path(\"fra-eng/fra.txt\")\n",
    "text_all = pathobj.read_text(encoding=\"utf-8\")\n",
    "lines = text_all.splitlines()\n",
    "train_data = [line.split(\"\\t\") for line in lines]\n",
    "train_data = np.array(train_data)[:,[1,0]]\n",
    "# print first row\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this training set, text length in the latter part is longer (and includes multiple sentences) than the former part.<br>\n",
    "Therefore I shuffle entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Quoi que vous fassiez, ne tirez pas sur cette corde !',\n",
       "       \"Whatever you do, don't pull this rope.\"], dtype='<U349')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(train_data)\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data consists of multiple sentences, it converts to a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tsmatsuz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.data\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "tokenizer_en = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "tokenizer_fr = nltk.data.load(\"tokenizers/punkt/french.pickle\")\n",
    "fr_list = []\n",
    "en_list = []\n",
    "for x in train_data:\n",
    "    x1 = tokenizer_fr.tokenize(x[0])\n",
    "    x2 = tokenizer_en.tokenize(x[1])\n",
    "    if len(x1) == len(x2):\n",
    "        fr_list += x1\n",
    "        en_list += x2\n",
    "train_data = np.column_stack((fr_list, en_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the better performance (accuracy), I standarize the input text as follows.\n",
    "- Make all words to lowercase in order to reduce words\n",
    "- Make \"-\" (hyphen) to space\n",
    "- Remove all punctuation except \" ' \" (e.g, Ken's bag, ces't, ...)\n",
    "\n",
    "> Note : To make simplify, I have skipped other pre-processing, such as, N-gram detection (see [this exercise](./05_ngram_cnn.ipynb)), polysemy processing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['quoi que vous fassiez ne tirez pas sur cette corde',\n",
       "       \"whatever you do don't pull this rope\"], dtype='<U250')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "train_data = np.char.lower(train_data)\n",
    "train_data = np.char.replace(train_data, \"-\", \" \")\n",
    "for x in string.punctuation.replace(\"'\", \"\"):\n",
    "    train_data = np.char.replace(train_data, x, \"\")\n",
    "for x in \"«»\":\n",
    "    train_data = np.char.replace(train_data, x, \"\")\n",
    "train_data = np.char.strip(train_data)\n",
    "# print first row\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ```[START]``` and ```[END]``` tokens in string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[START] quoi que vous fassiez ne tirez pas sur cette corde [END]',\n",
       "       \"[START] whatever you do don't pull this rope [END]\"],\n",
       "      dtype='<U264')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.array([[\" \".join([\"[START]\", x, \"[END]\"]), \" \".join([\"[START]\", y, \"[END]\"])] for x, y in train_data])\n",
    "# print first row\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sequence inputs\n",
    "\n",
    "We will generate the sequence of word's indices (i.e, tokenize) from text.\n",
    "\n",
    "![Index vectorize](images/index_vectorize2.png?raw=true)\n",
    "\n",
    "First, we build word's vectorizer for both source text (French) and target text (English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "max_word = 10000\n",
    "\n",
    "source_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_word,\n",
    "    output_sequence_length=None, # maximum length of sequences\n",
    "    output_mode=\"int\")\n",
    "source_vectorization.adapt(train_data[:,0])\n",
    "\n",
    "target_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_word,\n",
    "    output_sequence_length=None, # maximum length of sequences\n",
    "    output_mode=\"int\")\n",
    "target_vectorization.adapt(train_data[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we vectorize sentence into integer's sequence as follows.<br>\n",
    "In this example, we create fixed size of sequence (padded by 0) in each row.\n",
    "\n",
    "![Index vectorize](images/index_vectorize2.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[   3  117    8    7 1674   10 4527    6   63   54 1426    2    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0], shape=(45,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[   2  759    5   12   19 1428   16 1295    3    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0], shape=(38,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "train_source = source_vectorization(train_data[:,0])\n",
    "train_target = target_vectorization(train_data[:,1])\n",
    "# print first row\n",
    "print(train_source[0])\n",
    "print(train_target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make TensorFlow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_data = tf.data.Dataset.from_tensor_slices((train_source, train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate label (y) for training.\n",
    "\n",
    "As I have mentioned above, we should finally predict the next word in target sentence (English) using current word and encoded context.<br>\n",
    "We then create the following label (y) in each row.\n",
    "\n",
    "<u>input - list of current words</u> :\n",
    "```\n",
    "[2, 7, 5, 3, 0, ... , 0]\n",
    "```\n",
    "\n",
    "<u>output (y) - list of next words</u> :\n",
    "```\n",
    "[7, 5, 3, 0, 0, ... , 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** X *****\n",
      "(<tf.Tensor: shape=(45,), dtype=int64, numpy=\n",
      "array([   3,  117,    8,    7, 1674,   10, 4527,    6,   63,   54, 1426,\n",
      "          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0])>, <tf.Tensor: shape=(38,), dtype=int64, numpy=\n",
      "array([   2,  759,    5,   12,   19, 1428,   16, 1295,    3,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0])>)\n",
      "***** y *****\n",
      "tf.Tensor(\n",
      "[ 759    5   12   19 1428   16 1295    3    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0], shape=(38,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def add_label(x_source, x_target):\n",
    "    y = tf.slice(x_target, begin=[1], size=[len(x_target) - 1])\n",
    "    y = tf.concat([y, [0]], axis=0)\n",
    "    return (x_source, x_target), y\n",
    "train_tf_data = train_tf_data.map(lambda src, tar: add_label(src, tar))\n",
    "# print first row\n",
    "for x, y in train_tf_data.take(1):\n",
    "    print(\"***** X *****\")\n",
    "    print(x)\n",
    "    print(\"***** y *****\")\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert label y into one-hot vector (shape (max_word,)).\n",
    "\n",
    "y (before) :\n",
    "```\n",
    "[4, 1, 3, 0]\n",
    "```\n",
    "\n",
    "y (after) :\n",
    "```\n",
    "[\n",
    "  [0,0,0,0,1, ... ,0],\n",
    "  [0,1,0,0,0, ... ,0],\n",
    "  [0,0,0,1,0, ... ,0],\n",
    "  [1,0,0,0,0, ... ,0]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]], shape=(38, 10000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(x, y):\n",
    "    y_new = tf.one_hot(y, depth=max_word)\n",
    "    return x, y_new\n",
    "train_tf_data = train_tf_data.map(lambda x, y: to_one_hot(x, y))\n",
    "# print y in first row\n",
    "for x, y in train_tf_data.take(1):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Encoder-Decoder\n",
    "\n",
    "Now we build an attention model in encoder-decoder architecture as follows.\n",
    "\n",
    "- Outputs in RNN (for source text) are generated in encoder.\n",
    "- Encoder's outputs are used in attention architecture and passed into each unit in decoder's RNN.\n",
    "- Each RNN output in decoder is passed into dense (FCNet) layer and generate the sequence of next words.\n",
    "- Calculate loss between predicted next words and the true values of next words, and then proceed to train.\n",
    "\n",
    "![the trainer architecture of machine translation](./images/machine_translation2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build encoder model.\n",
    "\n",
    "In the following ```tf.keras.layers.GRU``` layer, the shape of RNN input is expected to be ```(batch_size, sequence_length, input_dimension)```. By setting ```stateful=True```, the last state at index i in batch is used as initial state for index i in the following batch.<br>\n",
    "Here we then set ```stateful=False```. (Because the sequence in the following batch doesn't depend on the sequence in previous batch.)\n",
    "\n",
    "Unlike [previous example](./07_encoder_decoder.ipynb), all outputs in sequence is used in the next model, and it should then return all outputs (not only the last output).<br>\n",
    "Therefore I set ```return_sequences=True``` in RNN (GRU layer).\n",
    "\n",
    "![all outputs in encoder](./images/encoder_all.png)\n",
    "\n",
    "Remind that the length of each sequence differs in each row and it's padded by zero.<br>\n",
    "Therefore, here I create mask, in which, the element is TRUE when it exists and FALSE when it's missing.<br>\n",
    "By passing mask into RNN, the computation will be skipped in FALSE elements.\n",
    "\n",
    "> Note : You can also set encoder's final state as decoder's initial state.<br>\n",
    "> In this example, I'll discard encoder's final state in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            self.vocab_size,\n",
    "            embedding_dim,\n",
    "            mask_zero=True,\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.rnn = tf.keras.layers.GRU(\n",
    "            rnn_units,\n",
    "            use_bias=True,\n",
    "            return_sequences=True,  # see above !\n",
    "            return_state=True,\n",
    "            stateful=False,  # not to inherit states between batches\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, states=None, training=False, return_state=False):\n",
    "        inputs_emb = self.embedding(inputs, training=training)\n",
    "        mask = self.embedding.compute_mask(inputs)\n",
    "        if states is None:\n",
    "            outputs, new_states = self.rnn(inputs_emb, mask=mask, training=training)\n",
    "        else:\n",
    "            outputs, new_states = self.rnn(inputs_emb, mask=mask, initial_state=states, training=training)\n",
    "        if return_state:\n",
    "            return outputs, new_states  # This is used in prediction\n",
    "        else:\n",
    "            return outputs              # This is used in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build decoder with attention architecture as follows. (The following variable ```alpha``` is attention weights at ```j```-th step.)\n",
    "\n",
    "As I have mentioned above, decoder receives encoder's outputs (outputs for all components in sequence), and this is commonly used in all steps in target sequence.\n",
    "\n",
    "In each steps in target RNN sequence, the state in previous step is used in attention layer. For the purpose of your learning, here I manually implement this loop of RNN steps from scratch as follows. (See the following ```for``` loop in attention process.)<br>\n",
    "However, you can use your custom RNN cell (one step cell in RNN) or use ```tfa.seq2seq.AttentionWrapper``` with ```tf.keras.layers.GRUCell``` to build this kind of RNN steps with attention in TensorFlow.\n",
    "\n",
    "The softmax operation should be masked in attention layer.\n",
    "\n",
    "![decoder with attention](./images/decoder_attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderWithAttention(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            self.vocab_size,\n",
    "            embedding_dim,\n",
    "            mask_zero=True,\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.attention_dense1 = tf.keras.layers.Dense(\n",
    "            rnn_units,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.attention_dense2 = tf.keras.layers.Dense(\n",
    "            1,\n",
    "            activation=None,\n",
    "        )\n",
    "        self.softmax = tf.keras.layers.Softmax(\n",
    "            axis=-1\n",
    "        )\n",
    "        self.rnn = tf.keras.layers.GRU(\n",
    "            rnn_units,\n",
    "            use_bias=True,\n",
    "            return_sequences=False,\n",
    "            return_state=True,\n",
    "            stateful=False,  # not to inherit states between batches\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.output_dense1 = tf.keras.layers.Dense(\n",
    "            rnn_units,\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "        self.output_dense2 = tf.keras.layers.Dense(\n",
    "            self.vocab_size,\n",
    "            activation=None,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, states=None, training=False, return_state=False):\n",
    "        inputs_target, enc_outputs = inputs\n",
    "\n",
    "        #\n",
    "        # get batch size and sequence size\n",
    "        #\n",
    "        batch_size = tf.shape(inputs_target)[0]\n",
    "        dec_sequence_size = tf.shape(inputs_target)[1]\n",
    "        enc_sequence_size = tf.shape(enc_outputs)[1]\n",
    "        mask = self.embedding.compute_mask(inputs_target)\n",
    "\n",
    "        #\n",
    "        # process embedding\n",
    "        #\n",
    "        inputs_emb = self.embedding(inputs_target, training=training) # shape: (batch_size, dec_sequence_size, embedding_dim)\n",
    "\n",
    "        #\n",
    "        # process attention\n",
    "        # (You can also use built-in tf.keras.layers.AdditiveAttention.)\n",
    "        #\n",
    "\n",
    "        # set initial state\n",
    "        if states is None:\n",
    "            current_states = tf.zeros([batch_size, rnn_units]) # you can also use self.rnn.get_initial_state(...)\n",
    "        else:\n",
    "            current_states = states\n",
    "        # loop sequence\n",
    "        rnn_outputs = []\n",
    "        for j in range(dec_sequence_size):\n",
    "            states_fill_sequence = tf.expand_dims(current_states, axis=1) # shape : (batch_size, 1, rnn_units)\n",
    "            states_fill_sequence = tf.tile(states_fill_sequence, multiples=[1,enc_sequence_size,1]) # shape : (batch_size, enc_sequence_size, rnn_units)\n",
    "            enc_and_states = tf.concat([states_fill_sequence, enc_outputs], axis=-1) # shape : (batch_size, enc_sequence_size, rnn_units * 2)\n",
    "            alpha = self.attention_dense1(enc_and_states, training=training) # shape : (batch_size, enc_sequence_size, rnn_units)\n",
    "            alpha = self.attention_dense2(alpha, training=training) # shape : (batch_size, enc_sequence_size, 1)\n",
    "            alpha = tf.squeeze(alpha, axis=2) # shape : (batch_size, enc_sequence_size)\n",
    "            ### use masking !\n",
    "            # alpha = tf.nn.softmax(alpha, axis=-1) # shape: (batch_size, enc_sequence_size)\n",
    "            attention_mask = enc_outputs._keras_mask\n",
    "            attention_mask = tf.cast(attention_mask, tf.float32) # True -> 1.0, False -> 0.0\n",
    "            alpha = self.softmax(alpha, attention_mask) # shape: (batch_size, enc_sequence_size)\n",
    "            c = tf.einsum(\"bs,bsu->bu\", alpha, enc_outputs) # shape: (batch_size, rnn_units)\n",
    "            emb_j = inputs_emb[:,j,:] # shape: (batch_size, embedding_dim)\n",
    "            input_j = tf.concat([c, emb_j], axis=-1) # shape: (batch_size, rnn_units + embedding_dim)\n",
    "            input_j = tf.expand_dims(input_j, axis=1) # shape: (batch_size, 1, rnn_units + embedding_dim)\n",
    "            mask_j = tf.expand_dims(mask[:,j], axis=1)\n",
    "            rnn_o, current_states = self.rnn(input_j, mask=mask_j, initial_state=current_states, training=training) # shape: (batch_size, rnn_units)\n",
    "            rnn_outputs.append(rnn_o)\n",
    "        rnn_outputs = tf.stack(rnn_outputs, axis=1) # shape: (batch_size, dec_sequence_size, rnn_units)\n",
    "\n",
    "        #\n",
    "        # process vocab outputs\n",
    "        #\n",
    "        outputs = self.output_dense1(rnn_outputs, training=training)\n",
    "        outputs = self.output_dense2(outputs, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return outputs, mask, current_states  # This is used in prediction\n",
    "        else:\n",
    "            return outputs, mask                  # This is used in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put it all together and run training.\n",
    "\n",
    "I note that the loss computation is also masked. (i.e, The loss is ignored in missing elements.)\n",
    "\n",
    "> Note : In the following example, I'm writing a training loop from scratch, but you can also build TensorFlow custom model for this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - loss   0.399578\n",
      "Epoch 2/5 - loss   0.463912\n",
      "Epoch 3/5 - loss   1.458908\n",
      "Epoch 4/5 - loss   0.642533\n",
      "Epoch 5/5 - loss   0.115093\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "n_epoch = 5\n",
    "shuffle_buffer_size = 5000\n",
    "train_batch_size = 64\n",
    "loss_records = []\n",
    "\n",
    "enc_model = Encoder(\n",
    "    vocab_size=max_word,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "dec_model = DecoderWithAttention(\n",
    "    vocab_size=max_word,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction=tf.keras.losses.Reduction.NONE\n",
    ")\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "### I don't use train_tf_data.repeat(n_epoch) and run shuffle in each epoch,\n",
    "### because I want to check result in each epoch\n",
    "for epoch in range(n_epoch):\n",
    "    tf_data_epoch = train_tf_data.shuffle(shuffle_buffer_size).batch(train_batch_size)\n",
    "    iterator = iter(tf_data_epoch)\n",
    "    while True:\n",
    "        with tf.GradientTape() as enc_tape, tf.GradientTape() as dec_tape:\n",
    "            # get next batch\n",
    "            try:\n",
    "                input_batch_x, input_batch_y = iterator.get_next()\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                loop_f = False\n",
    "                break\n",
    "            input_source, input_target = input_batch_x\n",
    "            # process encoder\n",
    "            enc_outputs = enc_model(\n",
    "                input_source,\n",
    "                training=True)\n",
    "            # process decoder\n",
    "            logits, mask = dec_model(\n",
    "                (input_target , enc_outputs),\n",
    "                training=True)\n",
    "            # calculate masked loss\n",
    "            loss = loss_func(\n",
    "                input_batch_y,\n",
    "                logits) # shape of loss is (batch_size, sequence_size)\n",
    "            mask_float = tf.cast(mask, tf.float32) # True -> 1.0, False -> 0.0\n",
    "            loss = loss * mask_float\n",
    "            loss = tf.math.reduce_sum(loss, axis=1) # shape of loss is (batch_size, )\n",
    "            loss = loss / tf.math.reduce_sum(mask_float, axis=1)\n",
    "            # get gradient\n",
    "            grad = enc_tape.gradient(\n",
    "                loss,\n",
    "                enc_model.trainable_variables+dec_model.trainable_variables\n",
    "            )\n",
    "        # apply gradient\n",
    "        opt.apply_gradients(zip(grad, enc_model.trainable_variables+dec_model.trainable_variables))\n",
    "        # record result\n",
    "        batch_average_loss = tf.math.reduce_mean(loss).numpy().tolist()\n",
    "        print(\"Epoch {}/{} - loss {loss:10.6f}\".format(epoch+1, n_epoch, loss=batch_average_loss), end=\"\\r\")\n",
    "        loss_records.append(batch_average_loss)\n",
    "    # add line break\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training has completed, show how loss is optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3230ff6400>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#loss_list = loss_records[:10000]\n",
    "loss_list = loss_records\n",
    "\n",
    "loss_average = []\n",
    "for i in range(len(loss_list)):\n",
    "    avg_list = np.empty(shape=(1,), dtype=int)\n",
    "    if i < 50:\n",
    "        avg_list = loss_list[:i+1]\n",
    "    else:\n",
    "        avg_list = loss_list[i-49:i+1]\n",
    "    loss_average.append(np.average(avg_list))\n",
    "plt.plot(loss_list)\n",
    "plt.plot(loss_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Text\n",
    "\n",
    "Now translate text (French) to English with trained model.<br>\n",
    "(All these sentences are not in training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def translate(sentence):\n",
    "    # preprocess french\n",
    "    input_text_fr = sentence\n",
    "    input_text_fr = input_text_fr.lower()\n",
    "    input_text_fr = \" \".join([\"[START]\", input_text_fr, \"[END]\"])\n",
    "\n",
    "    text_seq_fr = source_vectorization(input_text_fr)\n",
    "    text_seq_fr = tf.expand_dims(text_seq_fr, axis=0)\n",
    "\n",
    "    # process encoder\n",
    "    enc_outputs = enc_model(text_seq_fr)\n",
    "\n",
    "    # process decoder\n",
    "    vocab_list_en = target_vectorization.get_vocabulary()\n",
    "    states = None\n",
    "    prev_idx_en = target_vectorization(\"[START]\")\n",
    "    end_num_en = target_vectorization(\"[END]\").numpy().tolist()[0]\n",
    "    #text_seq_en = []\n",
    "    #text_seq_en = tf.expand_dims(text_seq_en[len(text_seq_en) - 1], axis=0)\n",
    "    while True:\n",
    "        y, mask, states = dec_model(\n",
    "            (tf.expand_dims(prev_idx_en, axis=0), enc_outputs),\n",
    "            states=states,\n",
    "            return_state=True)\n",
    "        prev_idx_en = np.argmax(y[0])\n",
    "        if prev_idx_en.item() == end_num_en:\n",
    "            break\n",
    "        print(vocab_list_en[prev_idx_en.item()], end=\" \")\n",
    "        prev_idx_en = tf.convert_to_tensor([prev_idx_en])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like the guitar \n",
      "\n",
      "he lives in japan \n",
      "\n",
      "this pen is used by him \n",
      "\n",
      "this is my favorite song \n",
      "\n",
      "he drives a car and goes to new york \n",
      "\n"
     ]
    }
   ],
   "source": [
    "translate(\"j'aime la guitare\") # i like guitar\n",
    "translate(\"il vit au japon\") # he lives in Japan\n",
    "translate(\"ce stylo est utilisé par lui\") # this pen is used by him\n",
    "translate(\"c'est ma chanson préférée\") # that's my favorite song\n",
    "translate(\"il conduit une voiture et va à new york\") # he drives a car and goes to new york"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
